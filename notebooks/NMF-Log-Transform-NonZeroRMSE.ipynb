{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef3efb2b",
   "metadata": {},
   "source": [
    "# Trial Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b075018b",
   "metadata": {},
   "source": [
    "Data preparation:\n",
    "- Filter genes with less than 10 non-zero expressions spots\n",
    "- Apply log transformation on the expressions\n",
    "\n",
    "Model:\n",
    "- Nueral Matrix Factorization\n",
    "- RMSE training loss excluding zeros\n",
    "\n",
    "Results:\n",
    "- Valid RMSE: \n",
    "- Test RMSE:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185bb069",
   "metadata": {
    "id": "rrsJ--rOj_yJ"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "411f99be",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 521,
     "status": "ok",
     "timestamp": 1645041280051,
     "user": {
      "displayName": "sofi budman",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjgwGJyBpmRHwEa349uQk-436Picyu2Y4sr1rMFSY0=s64",
      "userId": "09764764631934161053"
     },
     "user_tz": -120
    },
    "id": "CanD8ixgj_yK",
    "outputId": "b47fa8b5-afd2-47ed-dbc2-d39f2efef62e"
   },
   "outputs": [],
   "source": [
    "from os import path, listdir\n",
    "from copy import deepcopy\n",
    "import stlearn as st\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import trainer_nmf as trainer\n",
    "import data_nmf as get_data\n",
    "from models import get_model\n",
    "import tester_nmf as tester\n",
    "from loss import *\n",
    "from results_analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "532e3c62",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 618,
     "status": "ok",
     "timestamp": 1644504258886,
     "user": {
      "displayName": "sofi budman",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjgwGJyBpmRHwEa349uQk-436Picyu2Y4sr1rMFSY0=s64",
      "userId": "09764764631934161053"
     },
     "user_tz": -120
    },
    "id": "ueuPQkjoj_yL",
    "outputId": "80a13698-73f2-47f2-f861-57bdab6aa4a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "plt.rcParams.update({'font.size': 12})\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791e0071",
   "metadata": {},
   "source": [
    "# Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c46a5494",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_counts = 500\n",
    "min_cells = 177\n",
    "apply_log = True\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc1345d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/anndata/_core/anndata.py:1830: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# spots: 1185 | # genes: 32285\n",
      "New shape after filtering: (1185, 6279)\n",
      "Log transformation step is finished in adata.X\n",
      "Data shape: (7440615, 3)\n",
      "Number of genes: 6279\n",
      "Number of spots: 1185\n",
      "Train shape:(7440615, 3)\n",
      "Valid shape:(383754, 3)\n",
      "Test shape:(426393, 3)\n",
      "Start creating the DataSets\n",
      "Start creating the DataLoaders\n",
      "Finish loading the data\n"
     ]
    }
   ],
   "source": [
    "dl_train, dl_valid, dl_test, _ = get_data.main(\n",
    "    min_counts=min_counts,\n",
    "    min_cells=min_cells,\n",
    "    apply_log=apply_log, \n",
    "    batch_size=batch_size, \n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de31975",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03f1f55",
   "metadata": {},
   "source": [
    "## Set HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56d24159",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'NMF'\n",
    "max_epochs = 150\n",
    "early_stopping = 10\n",
    "model_params = {\n",
    "    'learning_rate': 0.1,\n",
    "    'optimizer': \"SGD\",\n",
    "    'latent_dim': 40,\n",
    "    'batch_size': batch_size\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fce2bca",
   "metadata": {},
   "source": [
    "## Build Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e52d0658",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(model_name, model_params, dl_train)\n",
    "optimizer = getattr(optim, model_params['optimizer'])(model.parameters(), lr=model_params['learning_rate'])\n",
    "criterion = NON_ZERO_RMSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12ef88a",
   "metadata": {},
   "source": [
    "## Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3d16a96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 12:29:24.270626: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-27 12:29:24.433514: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-27 12:29:24.433545: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-09-27 12:29:24.467287: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-09-27 12:29:25.388027: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-09-27 12:29:25.388174: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-09-27 12:29:25.388190: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch[1] Avg loss: 2.24\n",
      "Validation Results - Epoch[1] Avg loss: 2.29\n",
      "Training Results - Epoch[2] Avg loss: 1.39\n",
      "Validation Results - Epoch[2] Avg loss: 1.42\n",
      "Training Results - Epoch[3] Avg loss: 0.73\n",
      "Validation Results - Epoch[3] Avg loss: 0.74\n",
      "Training Results - Epoch[4] Avg loss: 0.37\n",
      "Validation Results - Epoch[4] Avg loss: 0.38\n",
      "Training Results - Epoch[5] Avg loss: 0.36\n",
      "Validation Results - Epoch[5] Avg loss: 0.37\n",
      "Training Results - Epoch[6] Avg loss: 0.36\n",
      "Validation Results - Epoch[6] Avg loss: 0.37\n",
      "Training Results - Epoch[7] Avg loss: 0.36\n",
      "Validation Results - Epoch[7] Avg loss: 0.37\n",
      "Training Results - Epoch[8] Avg loss: 0.36\n",
      "Validation Results - Epoch[8] Avg loss: 0.37\n",
      "Training Results - Epoch[9] Avg loss: 0.36\n",
      "Validation Results - Epoch[9] Avg loss: 0.37\n",
      "Training Results - Epoch[10] Avg loss: 0.36\n",
      "Validation Results - Epoch[10] Avg loss: 0.37\n",
      "Training Results - Epoch[11] Avg loss: 0.36\n",
      "Validation Results - Epoch[11] Avg loss: 0.37\n",
      "Training Results - Epoch[12] Avg loss: 0.36\n",
      "Validation Results - Epoch[12] Avg loss: 0.37\n",
      "Training Results - Epoch[13] Avg loss: 0.36\n",
      "Validation Results - Epoch[13] Avg loss: 0.37\n",
      "Training Results - Epoch[14] Avg loss: 0.36\n",
      "Validation Results - Epoch[14] Avg loss: 0.37\n",
      "Training Results - Epoch[15] Avg loss: 0.36\n",
      "Validation Results - Epoch[15] Avg loss: 0.37\n",
      "Training Results - Epoch[16] Avg loss: 0.36\n",
      "Validation Results - Epoch[16] Avg loss: 0.36\n",
      "Training Results - Epoch[17] Avg loss: 0.36\n",
      "Validation Results - Epoch[17] Avg loss: 0.36\n",
      "Training Results - Epoch[18] Avg loss: 0.36\n",
      "Validation Results - Epoch[18] Avg loss: 0.36\n",
      "Training Results - Epoch[19] Avg loss: 0.36\n",
      "Validation Results - Epoch[19] Avg loss: 0.36\n",
      "Training Results - Epoch[20] Avg loss: 0.36\n",
      "Validation Results - Epoch[20] Avg loss: 0.36\n",
      "Training Results - Epoch[21] Avg loss: 0.36\n",
      "Validation Results - Epoch[21] Avg loss: 0.36\n",
      "Training Results - Epoch[22] Avg loss: 0.36\n",
      "Validation Results - Epoch[22] Avg loss: 0.36\n",
      "Training Results - Epoch[23] Avg loss: 0.36\n",
      "Validation Results - Epoch[23] Avg loss: 0.36\n",
      "Training Results - Epoch[24] Avg loss: 0.36\n",
      "Validation Results - Epoch[24] Avg loss: 0.36\n",
      "Training Results - Epoch[25] Avg loss: 0.36\n",
      "Validation Results - Epoch[25] Avg loss: 0.36\n",
      "Training Results - Epoch[26] Avg loss: 0.36\n",
      "Validation Results - Epoch[26] Avg loss: 0.36\n",
      "Training Results - Epoch[27] Avg loss: 0.36\n",
      "Validation Results - Epoch[27] Avg loss: 0.36\n",
      "Training Results - Epoch[28] Avg loss: 0.35\n",
      "Validation Results - Epoch[28] Avg loss: 0.36\n",
      "Training Results - Epoch[29] Avg loss: 0.35\n",
      "Validation Results - Epoch[29] Avg loss: 0.36\n",
      "Training Results - Epoch[30] Avg loss: 0.35\n",
      "Validation Results - Epoch[30] Avg loss: 0.36\n",
      "Training Results - Epoch[31] Avg loss: 0.35\n",
      "Validation Results - Epoch[31] Avg loss: 0.36\n",
      "Training Results - Epoch[32] Avg loss: 0.35\n",
      "Validation Results - Epoch[32] Avg loss: 0.36\n",
      "Training Results - Epoch[33] Avg loss: 0.35\n",
      "Validation Results - Epoch[33] Avg loss: 0.36\n",
      "Training Results - Epoch[34] Avg loss: 0.35\n",
      "Validation Results - Epoch[34] Avg loss: 0.36\n",
      "Training Results - Epoch[35] Avg loss: 0.35\n",
      "Validation Results - Epoch[35] Avg loss: 0.36\n",
      "Training Results - Epoch[36] Avg loss: 0.35\n",
      "Validation Results - Epoch[36] Avg loss: 0.36\n",
      "Training Results - Epoch[37] Avg loss: 0.35\n",
      "Validation Results - Epoch[37] Avg loss: 0.36\n",
      "Training Results - Epoch[38] Avg loss: 0.35\n",
      "Validation Results - Epoch[38] Avg loss: 0.36\n",
      "Training Results - Epoch[39] Avg loss: 0.35\n",
      "Validation Results - Epoch[39] Avg loss: 0.36\n",
      "Training Results - Epoch[40] Avg loss: 0.35\n",
      "Validation Results - Epoch[40] Avg loss: 0.35\n",
      "Training Results - Epoch[41] Avg loss: 0.35\n",
      "Validation Results - Epoch[41] Avg loss: 0.35\n",
      "Training Results - Epoch[42] Avg loss: 0.35\n",
      "Validation Results - Epoch[42] Avg loss: 0.35\n",
      "Training Results - Epoch[43] Avg loss: 0.35\n",
      "Validation Results - Epoch[43] Avg loss: 0.35\n",
      "Training Results - Epoch[44] Avg loss: 0.35\n",
      "Validation Results - Epoch[44] Avg loss: 0.35\n",
      "Training Results - Epoch[45] Avg loss: 0.35\n",
      "Validation Results - Epoch[45] Avg loss: 0.35\n",
      "Training Results - Epoch[46] Avg loss: 0.34\n",
      "Validation Results - Epoch[46] Avg loss: 0.35\n",
      "Training Results - Epoch[47] Avg loss: 0.34\n",
      "Validation Results - Epoch[47] Avg loss: 0.35\n",
      "Training Results - Epoch[48] Avg loss: 0.34\n",
      "Validation Results - Epoch[48] Avg loss: 0.35\n",
      "Training Results - Epoch[49] Avg loss: 0.34\n",
      "Validation Results - Epoch[49] Avg loss: 0.35\n",
      "Training Results - Epoch[50] Avg loss: 0.34\n",
      "Validation Results - Epoch[50] Avg loss: 0.35\n",
      "Training Results - Epoch[51] Avg loss: 0.34\n",
      "Validation Results - Epoch[51] Avg loss: 0.35\n",
      "Training Results - Epoch[52] Avg loss: 0.34\n",
      "Validation Results - Epoch[52] Avg loss: 0.35\n",
      "Training Results - Epoch[53] Avg loss: 0.34\n",
      "Validation Results - Epoch[53] Avg loss: 0.35\n",
      "Training Results - Epoch[54] Avg loss: 0.34\n",
      "Validation Results - Epoch[54] Avg loss: 0.35\n",
      "Training Results - Epoch[55] Avg loss: 0.34\n",
      "Validation Results - Epoch[55] Avg loss: 0.35\n",
      "Training Results - Epoch[57] Avg loss: 0.34\n",
      "Validation Results - Epoch[57] Avg loss: 0.35\n",
      "Training Results - Epoch[58] Avg loss: 0.34\n",
      "Validation Results - Epoch[58] Avg loss: 0.35\n",
      "Training Results - Epoch[59] Avg loss: 0.34\n",
      "Validation Results - Epoch[59] Avg loss: 0.35\n",
      "Training Results - Epoch[60] Avg loss: 0.34\n",
      "Validation Results - Epoch[60] Avg loss: 0.35\n",
      "Training Results - Epoch[61] Avg loss: 0.34\n",
      "Validation Results - Epoch[61] Avg loss: 0.35\n",
      "Training Results - Epoch[63] Avg loss: 0.34\n",
      "Validation Results - Epoch[63] Avg loss: 0.35\n",
      "Training Results - Epoch[64] Avg loss: 0.34\n",
      "Validation Results - Epoch[64] Avg loss: 0.35\n",
      "Training Results - Epoch[65] Avg loss: 0.34\n",
      "Validation Results - Epoch[65] Avg loss: 0.35\n",
      "Training Results - Epoch[66] Avg loss: 0.34\n",
      "Validation Results - Epoch[66] Avg loss: 0.34\n",
      "Training Results - Epoch[67] Avg loss: 0.34\n",
      "Validation Results - Epoch[67] Avg loss: 0.34\n",
      "Training Results - Epoch[68] Avg loss: 0.34\n",
      "Validation Results - Epoch[68] Avg loss: 0.34\n",
      "Training Results - Epoch[69] Avg loss: 0.34\n",
      "Validation Results - Epoch[69] Avg loss: 0.34\n",
      "Training Results - Epoch[70] Avg loss: 0.34\n",
      "Validation Results - Epoch[70] Avg loss: 0.34\n",
      "Training Results - Epoch[71] Avg loss: 0.34\n",
      "Validation Results - Epoch[71] Avg loss: 0.34\n",
      "Training Results - Epoch[72] Avg loss: 0.34\n",
      "Validation Results - Epoch[72] Avg loss: 0.34\n",
      "Training Results - Epoch[73] Avg loss: 0.34\n",
      "Validation Results - Epoch[73] Avg loss: 0.34\n",
      "Training Results - Epoch[74] Avg loss: 0.34\n",
      "Validation Results - Epoch[74] Avg loss: 0.34\n",
      "Training Results - Epoch[75] Avg loss: 0.34\n",
      "Validation Results - Epoch[75] Avg loss: 0.34\n",
      "Training Results - Epoch[76] Avg loss: 0.34\n",
      "Validation Results - Epoch[76] Avg loss: 0.34\n",
      "Training Results - Epoch[77] Avg loss: 0.34\n",
      "Validation Results - Epoch[77] Avg loss: 0.34\n",
      "Training Results - Epoch[78] Avg loss: 0.34\n",
      "Validation Results - Epoch[78] Avg loss: 0.34\n",
      "Training Results - Epoch[79] Avg loss: 0.34\n",
      "Validation Results - Epoch[79] Avg loss: 0.34\n",
      "Training Results - Epoch[80] Avg loss: 0.34\n",
      "Validation Results - Epoch[80] Avg loss: 0.34\n",
      "Training Results - Epoch[82] Avg loss: 0.34\n",
      "Validation Results - Epoch[82] Avg loss: 0.34\n",
      "Training Results - Epoch[83] Avg loss: 0.34\n",
      "Validation Results - Epoch[83] Avg loss: 0.34\n",
      "Training Results - Epoch[84] Avg loss: 0.34\n",
      "Validation Results - Epoch[84] Avg loss: 0.34\n",
      "Training Results - Epoch[85] Avg loss: 0.33\n",
      "Validation Results - Epoch[85] Avg loss: 0.34\n",
      "Training Results - Epoch[86] Avg loss: 0.33\n",
      "Validation Results - Epoch[86] Avg loss: 0.34\n",
      "Training Results - Epoch[87] Avg loss: 0.33\n",
      "Validation Results - Epoch[87] Avg loss: 0.34\n",
      "Training Results - Epoch[88] Avg loss: 0.33\n",
      "Validation Results - Epoch[88] Avg loss: 0.34\n",
      "Training Results - Epoch[89] Avg loss: 0.33\n",
      "Validation Results - Epoch[89] Avg loss: 0.34\n",
      "Training Results - Epoch[91] Avg loss: 0.33\n",
      "Validation Results - Epoch[91] Avg loss: 0.34\n",
      "Training Results - Epoch[92] Avg loss: 0.33\n",
      "Validation Results - Epoch[92] Avg loss: 0.34\n",
      "Training Results - Epoch[93] Avg loss: 0.33\n",
      "Validation Results - Epoch[93] Avg loss: 0.34\n",
      "Training Results - Epoch[94] Avg loss: 0.33\n",
      "Validation Results - Epoch[94] Avg loss: 0.34\n",
      "Training Results - Epoch[95] Avg loss: 0.33\n",
      "Validation Results - Epoch[95] Avg loss: 0.34\n",
      "Training Results - Epoch[96] Avg loss: 0.33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch[96] Avg loss: 0.34\n",
      "Training Results - Epoch[97] Avg loss: 0.33\n",
      "Validation Results - Epoch[97] Avg loss: 0.34\n",
      "Training Results - Epoch[98] Avg loss: 0.33\n",
      "Validation Results - Epoch[98] Avg loss: 0.34\n",
      "Training Results - Epoch[99] Avg loss: 0.33\n",
      "Validation Results - Epoch[99] Avg loss: 0.34\n",
      "Training Results - Epoch[100] Avg loss: 0.33\n",
      "Validation Results - Epoch[100] Avg loss: 0.34\n",
      "Training Results - Epoch[102] Avg loss: 0.33\n",
      "Validation Results - Epoch[102] Avg loss: 0.34\n",
      "Training Results - Epoch[103] Avg loss: 0.33\n",
      "Validation Results - Epoch[103] Avg loss: 0.34\n",
      "Training Results - Epoch[104] Avg loss: 0.33\n",
      "Validation Results - Epoch[104] Avg loss: 0.34\n",
      "Training Results - Epoch[105] Avg loss: 0.33\n",
      "Validation Results - Epoch[105] Avg loss: 0.34\n",
      "Training Results - Epoch[106] Avg loss: 0.33\n",
      "Validation Results - Epoch[106] Avg loss: 0.34\n",
      "Training Results - Epoch[108] Avg loss: 0.33\n",
      "Validation Results - Epoch[108] Avg loss: 0.34\n",
      "Training Results - Epoch[109] Avg loss: 0.33\n",
      "Validation Results - Epoch[109] Avg loss: 0.34\n",
      "Training Results - Epoch[110] Avg loss: 0.33\n",
      "Validation Results - Epoch[110] Avg loss: 0.34\n",
      "Training Results - Epoch[111] Avg loss: 0.33\n",
      "Validation Results - Epoch[111] Avg loss: 0.34\n",
      "Training Results - Epoch[112] Avg loss: 0.33\n",
      "Validation Results - Epoch[112] Avg loss: 0.34\n",
      "Training Results - Epoch[113] Avg loss: 0.33\n",
      "Validation Results - Epoch[113] Avg loss: 0.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Engine run is terminating due to exception: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model, valid_loss \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[1;32m      2\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      3\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[1;32m      4\u001b[0m     criterion\u001b[38;5;241m=\u001b[39mcriterion,\n\u001b[1;32m      5\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39mmax_epochs,\n\u001b[1;32m      6\u001b[0m     early_stopping\u001b[38;5;241m=\u001b[39mearly_stopping,\n\u001b[1;32m      7\u001b[0m     dl_train\u001b[38;5;241m=\u001b[39mdl_train,\n\u001b[1;32m      8\u001b[0m     dl_test\u001b[38;5;241m=\u001b[39mdl_valid, \n\u001b[1;32m      9\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m     10\u001b[0m     model_name\u001b[38;5;241m=\u001b[39mmodel_name\n\u001b[1;32m     11\u001b[0m )\n",
      "File \u001b[0;32m/FPST/src/trainer_nmf.py:132\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, criterion, max_epochs, early_stopping, dl_train, dl_test, device, model_name)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# Run the trainer\u001b[39;00m\n\u001b[1;32m    130\u001b[0m trainer\u001b[38;5;241m.\u001b[39mrun(dl_train, max_epochs\u001b[38;5;241m=\u001b[39mmax_epochs)\n\u001b[0;32m--> 132\u001b[0m tb_logger\u001b[38;5;241m.\u001b[39mclose()   \u001b[38;5;66;03m# Close logger\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# Return the best validation score\u001b[39;00m\n\u001b[1;32m    134\u001b[0m best_val_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mhandler\u001b[38;5;241m.\u001b[39mbest_score\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/ignite/engine/engine.py:704\u001b[0m, in \u001b[0;36mEngine.run\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch_length should be provided if data is None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mdataloader \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m--> 704\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/ignite/engine/engine.py:783\u001b[0m, in \u001b[0;36mEngine._internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine run is terminating due to exception: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 783\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/ignite/engine/engine.py:466\u001b[0m, in \u001b[0;36mEngine._handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED, e)\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 466\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/ignite/engine/engine.py:753\u001b[0m, in \u001b[0;36mEngine._internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    751\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_engine()\n\u001b[0;32m--> 753\u001b[0m time_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_once_on_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[38;5;66;03m# time is available for handlers but must be update after fire\u001b[39;00m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mtimes[Events\u001b[38;5;241m.\u001b[39mEPOCH_COMPLETED\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m time_taken\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/ignite/engine/engine.py:807\u001b[0m, in \u001b[0;36mEngine._run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_event_name \u001b[38;5;241m!=\u001b[39m Events\u001b[38;5;241m.\u001b[39mDATALOADER_STOP_ITERATION:\n\u001b[1;32m    806\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mGET_BATCH_STARTED)\n\u001b[0;32m--> 807\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mbatch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mGET_BATCH_COMPLETED)\n\u001b[1;32m    809\u001b[0m iter_counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:569\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 569\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    570\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter._next_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_index\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 521\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sampler_iter\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/torch/utils/data/sampler.py:226\u001b[0m, in \u001b[0;36mBatchSampler.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[List[\u001b[38;5;28mint\u001b[39m]]:\n\u001b[1;32m    225\u001b[0m     batch \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 226\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler:\n\u001b[1;32m    227\u001b[0m         batch\u001b[38;5;241m.\u001b[39mappend(idx)\n\u001b[1;32m    228\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batch) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/torch/utils/data/sampler.py:123\u001b[0m, in \u001b[0;36mRandomSampler.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n):\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mrandperm(n, generator\u001b[38;5;241m=\u001b[39mgenerator)\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandperm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m%\u001b[39m n]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model, valid_loss = trainer.train(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    max_epochs=max_epochs,\n",
    "    early_stopping=early_stopping,\n",
    "    dl_train=dl_train,\n",
    "    dl_test=dl_valid, \n",
    "    device=device,\n",
    "    model_name=model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4971d3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_res = 0.67\n",
    "valid_res = 0.67\n",
    "print(f'Train final results (after log transform) = {train_res}')\n",
    "print(f'Train final results = {np.exp(train_res)}')\n",
    "print(f'Valid final results (after log transform) = {valid_res}')\n",
    "print(f'Valid final results = {np.exp(valid_res)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3dae77",
   "metadata": {},
   "source": [
    "## Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5b27f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, df_test_preds = tester.test(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    dl_test=dl_test,\n",
    "    device=device\n",
    ")\n",
    "print(f'Test loss = {test_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04df3332",
   "metadata": {},
   "source": [
    "# Results Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bce3852",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_preds['y_fixed'] = np.exp(df_test_preds['y'])\n",
    "df_test_preds['y_pred_fixed'] = np.exp(df_test_preds['y_pred'])\n",
    "\n",
    "y_col = 'y'\n",
    "y_pred_col = 'y_pred'\n",
    "\n",
    "df_test_preds['error'] = df_test_preds[y_col] - df_test_preds[y_pred_col]\n",
    "df_test_preds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe3fc25",
   "metadata": {},
   "source": [
    "## Errors Distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817ced53",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_distribution(df_test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11102841",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_test_preds['error'] > -1e5\n",
    "error_distribution(df_test_preds, mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e044a593",
   "metadata": {},
   "source": [
    "## Spots Errors Distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7dfc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "spots_error_distribution(df_test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e713b8bd",
   "metadata": {},
   "source": [
    "## Genes Errors Distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc3ceaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_error_distribution(df_test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c286c9cd",
   "metadata": {},
   "source": [
    "## Errors Heat Map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56a8941",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_heat_map(df_test_preds, vmin=-700, vmax=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d9aaea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
