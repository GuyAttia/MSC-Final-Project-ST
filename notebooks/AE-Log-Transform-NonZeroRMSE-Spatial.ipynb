{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef3efb2b",
   "metadata": {},
   "source": [
    "# Trial Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b075018b",
   "metadata": {},
   "source": [
    "Data preparation:\n",
    "- Filter genes with less than 10 non-zero expressions spots\n",
    "- Apply log transformation on the expressions\n",
    "\n",
    "Model:\n",
    "- Auto Encoders - encoding genes\n",
    "- RMSE training loss excluding zeros\n",
    "- Loss including SPATIAL regularaization\n",
    "\n",
    "Results:\n",
    "- Valid RMSE: \n",
    "- Test RMSE:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185bb069",
   "metadata": {
    "id": "rrsJ--rOj_yJ"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "411f99be",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 521,
     "status": "ok",
     "timestamp": 1645041280051,
     "user": {
      "displayName": "sofi budman",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjgwGJyBpmRHwEa349uQk-436Picyu2Y4sr1rMFSY0=s64",
      "userId": "09764764631934161053"
     },
     "user_tz": -120
    },
    "id": "CanD8ixgj_yK",
    "outputId": "b47fa8b5-afd2-47ed-dbc2-d39f2efef62e"
   },
   "outputs": [],
   "source": [
    "from os import path, listdir\n",
    "from copy import deepcopy\n",
    "import stlearn as st\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import trainer_ae as trainer\n",
    "import data_ae as get_data\n",
    "from models import get_model\n",
    "import tester_ae as tester\n",
    "from loss import *\n",
    "from results_analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "532e3c62",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 618,
     "status": "ok",
     "timestamp": 1644504258886,
     "user": {
      "displayName": "sofi budman",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjgwGJyBpmRHwEa349uQk-436Picyu2Y4sr1rMFSY0=s64",
      "userId": "09764764631934161053"
     },
     "user_tz": -120
    },
    "id": "ueuPQkjoj_yL",
    "outputId": "80a13698-73f2-47f2-f861-57bdab6aa4a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "plt.rcParams.update({'font.size': 12})\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791e0071",
   "metadata": {},
   "source": [
    "# Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c46a5494",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_counts = 500\n",
    "min_cells = 177\n",
    "apply_log = True\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc1345d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/anndata/_core/anndata.py:1830: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# spots: 1185 | # genes: 32285\n",
      "New shape after filtering: (1185, 6279)\n",
      "Log transformation step is finished in adata.X\n",
      "Data shape: (7440615, 3)\n",
      "Number of genes: 6279\n",
      "Number of spots: 1185\n",
      "Train shape:(7440615, 3)\n",
      "Valid shape:(7440615, 4)\n",
      "Test shape:(7440615, 4)\n",
      "Finish loading the data\n"
     ]
    }
   ],
   "source": [
    "dl_train, dl_valid, dl_test, df_spots_neighbors = get_data.main(\n",
    "    min_counts=min_counts,\n",
    "    min_cells=min_cells,\n",
    "    apply_log=apply_log, \n",
    "    batch_size=batch_size, \n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de31975",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03f1f55",
   "metadata": {},
   "source": [
    "## Set HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56d24159",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'AE'\n",
    "max_epochs = 150\n",
    "early_stopping = 5\n",
    "model_params = {\n",
    "    'learning_rate': 0.1,\n",
    "    'optimizer': \"SGD\",\n",
    "    'latent_dim': 40,\n",
    "    'batch_size': batch_size\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fce2bca",
   "metadata": {},
   "source": [
    "## Build Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e52d0658",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(model_name, model_params, dl_train)\n",
    "optimizer = getattr(optim, model_params['optimizer'])(model.parameters(), lr=model_params['learning_rate'])\n",
    "criterion = NON_ZERO_RMSELoss_Spatial_AE(df_spots_neighbors=df_spots_neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12ef88a",
   "metadata": {},
   "source": [
    "## Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3d16a96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 14:30:06.842973: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-27 14:30:07.071143: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-27 14:30:07.071214: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-09-27 14:30:07.134903: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-09-27 14:30:08.552241: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-09-27 14:30:08.552450: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-09-27 14:30:08.552477: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Current run is terminating due to exception: inconsistent tensor size, expected tensor [151680] and src [1185] to have the same number of elements, but got 151680 and 1185 elements respectively\n",
      "Engine run is terminating due to exception: inconsistent tensor size, expected tensor [151680] and src [1185] to have the same number of elements, but got 151680 and 1185 elements respectively\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "inconsistent tensor size, expected tensor [151680] and src [1185] to have the same number of elements, but got 151680 and 1185 elements respectively",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model, valid_loss \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[1;32m      2\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      3\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[1;32m      4\u001b[0m     criterion\u001b[38;5;241m=\u001b[39mcriterion,\n\u001b[1;32m      5\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39mmax_epochs,\n\u001b[1;32m      6\u001b[0m     early_stopping\u001b[38;5;241m=\u001b[39mearly_stopping,\n\u001b[1;32m      7\u001b[0m     dl_train\u001b[38;5;241m=\u001b[39mdl_train,\n\u001b[1;32m      8\u001b[0m     dl_test\u001b[38;5;241m=\u001b[39mdl_valid, \n\u001b[1;32m      9\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[1;32m     10\u001b[0m )\n",
      "File \u001b[0;32m/FPST/src/trainer_ae.py:128\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, criterion, max_epochs, early_stopping, dl_train, dl_test, device)\u001b[0m\n\u001b[1;32m    119\u001b[0m     tb_logger\u001b[38;5;241m.\u001b[39mattach_output_handler(\n\u001b[1;32m    120\u001b[0m         evaluator,\n\u001b[1;32m    121\u001b[0m         event_name\u001b[38;5;241m=\u001b[39mEvents\u001b[38;5;241m.\u001b[39mEPOCH_COMPLETED,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    124\u001b[0m         global_step_transform\u001b[38;5;241m=\u001b[39mglobal_step_from_engine(trainer),\n\u001b[1;32m    125\u001b[0m     )\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# Run the trainer\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m tb_logger\u001b[38;5;241m.\u001b[39mclose()   \u001b[38;5;66;03m# Close logger\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# Return the best validation score\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/ignite/engine/engine.py:704\u001b[0m, in \u001b[0;36mEngine.run\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch_length should be provided if data is None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mdataloader \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m--> 704\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/ignite/engine/engine.py:783\u001b[0m, in \u001b[0;36mEngine._internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine run is terminating due to exception: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 783\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/ignite/engine/engine.py:466\u001b[0m, in \u001b[0;36mEngine._handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED, e)\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 466\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/ignite/engine/engine.py:753\u001b[0m, in \u001b[0;36mEngine._internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    751\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_engine()\n\u001b[0;32m--> 753\u001b[0m time_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_once_on_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[38;5;66;03m# time is available for handlers but must be update after fire\u001b[39;00m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mtimes[Events\u001b[38;5;241m.\u001b[39mEPOCH_COMPLETED\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m time_taken\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/ignite/engine/engine.py:854\u001b[0m, in \u001b[0;36mEngine._run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent run is terminating due to exception: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 854\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/ignite/engine/engine.py:466\u001b[0m, in \u001b[0;36mEngine._handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED, e)\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 466\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/ignite/engine/engine.py:840\u001b[0m, in \u001b[0;36mEngine._run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39miteration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mITERATION_STARTED)\n\u001b[0;32m--> 840\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mITERATION_COMPLETED)\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_terminate \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_terminate_single_epoch:\n",
      "File \u001b[0;32m/FPST/src/trainer_ae.py:30\u001b[0m, in \u001b[0;36mtrain.<locals>.train_step\u001b[0;34m(engine, batch)\u001b[0m\n\u001b[1;32m     28\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     29\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[0;32m---> 30\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[1;32m     33\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/FPST/src/loss.py:99\u001b[0m, in \u001b[0;36mNON_ZERO_RMSELoss_Spatial_AE.forward\u001b[0;34m(self, yhat, y, batch_mask, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# Iterate over all spots and find their neighbors sum loss\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, spot_neighbors \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspots_neighbors_tensor):\n\u001b[0;32m---> 99\u001b[0m     spatial_loss_tensor[:, i] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msquared_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspot_neighbors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m spatial_loss_non_zeros \u001b[38;5;241m=\u001b[39m spatial_loss_tensor[non_zero_mask]    \u001b[38;5;66;03m# Keep only non zero in y_hat\u001b[39;00m\n\u001b[1;32m    103\u001b[0m total_squared_error \u001b[38;5;241m=\u001b[39m non_zero_error \u001b[38;5;241m+\u001b[39m spatial_loss_non_zeros\n",
      "\u001b[0;31mRuntimeError\u001b[0m: inconsistent tensor size, expected tensor [151680] and src [1185] to have the same number of elements, but got 151680 and 1185 elements respectively"
     ]
    }
   ],
   "source": [
    "model, valid_loss = trainer.train(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    max_epochs=max_epochs,\n",
    "    early_stopping=early_stopping,\n",
    "    dl_train=dl_train,\n",
    "    dl_test=dl_valid, \n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecbfc280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train final results (after log transform) = 0.73\n",
      "Train final results = 2.0750806076741224\n",
      "Valid final results (after log transform) = 0.74\n",
      "Valid final results = 2.0959355144943643\n"
     ]
    }
   ],
   "source": [
    "train_res = 0.73\n",
    "valid_res = 0.74\n",
    "print(f'Train final results (after log transform) = {train_res}')\n",
    "print(f'Train final results = {np.exp(train_res)}')\n",
    "print(f'Valid final results (after log transform) = {valid_res}')\n",
    "print(f'Valid final results = {np.exp(valid_res)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3dae77",
   "metadata": {},
   "source": [
    "## Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df5b27f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss = 0.0058470191434025764\n",
      "Test loss after exponent = 1.005864143371582\n"
     ]
    }
   ],
   "source": [
    "test_loss, df_test_preds = tester.test(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    dl_test=dl_test,\n",
    "    device=device\n",
    ")\n",
    "print(f'Test loss = {test_loss}')\n",
    "print(f'Test loss after exponent = {torch.exp(test_loss)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04df3332",
   "metadata": {},
   "source": [
    "# Results Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2b03aa",
   "metadata": {},
   "source": [
    "## Errors Distribution "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7022bd",
   "metadata": {},
   "source": [
    "## Spots Errors Distribution "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919f7a39",
   "metadata": {},
   "source": [
    "## Genes Errors Distribution "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6226f4c3",
   "metadata": {},
   "source": [
    "## Errors Heat Map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d9aaea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
